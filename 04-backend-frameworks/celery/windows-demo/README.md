Celery+Redis+FastAPI å¼‚æ­¥ä»»åŠ¡å›è°ƒæµ‹è¯•æ“ä½œæ–‡æ¡£
ä¸€ã€æµ‹è¯•æ¦‚è¿°

1. æµ‹è¯•ç›®æ ‡
   éªŒè¯åŸºäº Celery+Redis çš„å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—èƒ½åŠ›ï¼Œä»¥åŠ FastAPI æ¥å£çš„å›è°ƒæœºåˆ¶ï¼š

- FastAPI æ¥æ”¶çŸ­æ—¶é—´å†… 1000 æ¬¡ä»»åŠ¡æäº¤è¯·æ±‚ï¼Œå°†ä»»åŠ¡å­˜å…¥ Redis é˜Ÿåˆ—ï¼›
- Celery Worker ä»¥å•è¿›ç¨‹æ–¹å¼ä¾æ¬¡å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ï¼ˆæ’é˜Ÿæ‰§è¡Œï¼‰ï¼›
- æ¯ä¸ªä»»åŠ¡å¤„ç†å®Œæˆåï¼Œé€šè¿‡ HTTP å›è°ƒå°†ç»“æœå‘é€è‡³ç‹¬ç«‹çš„ FastAPI å›è°ƒæœåŠ¡ã€‚

2. æ ¸å¿ƒç»„ä»¶åŠåˆ†å·¥
   | ç»„ä»¶ | ä½œç”¨ | ç«¯å£ | å¯åŠ¨å‘½ä»¤ |
   |---------------------|----------------------------------------|-------|-----------------------------------------------|
   | Redis | ä½œä¸º Celery çš„æ¶ˆæ¯é˜Ÿåˆ—å’Œç»“æœå­˜å‚¨ | 6379 | æœ¬åœ°å¯åŠ¨ Redisï¼ˆé»˜è®¤é…ç½®ï¼‰ |
   | FastAPI ä¸»æœåŠ¡ | æ¥æ”¶ä»»åŠ¡æäº¤ã€æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ | 8000 | uvicorn main_api:app --host 0.0.0.0 --port 8000 |
   | FastAPI å›è°ƒæœåŠ¡ | æ¥æ”¶ä»»åŠ¡å¤„ç†å®Œæˆåçš„å›è°ƒæ•°æ® | 8001 | uvicorn callback_receiver:app --host 0.0.0.0 --port 8001 |
   | Celery Worker | æ¶ˆè´¹ Redis é˜Ÿåˆ—ä»»åŠ¡ï¼Œä¾æ¬¡å¤„ç†å¹¶è§¦å‘å›è°ƒ | - | - |

è¡¥å……è¯´æ˜ï¼š

- Celery Worker æ— å›ºå®šç«¯å£ï¼ˆå…¶é€šè¿‡ Redis ä¸å…¶ä»–ç»„ä»¶é€šä¿¡ï¼Œéç«¯å£ç›‘å¬æ¨¡å¼ï¼‰ï¼Œå› æ­¤ç«¯å£åˆ—å¡« `-`ï¼›
- è‹¥éœ€è¡¥å…… Celery Worker å¯åŠ¨å‘½ä»¤ï¼Œå¯å‚è€ƒå…¸å‹å†™æ³•ï¼š`celery -A celery_worker worker --loglevel=info`ï¼ˆéœ€æ ¹æ®å®é™…é¡¹ç›®çš„ Celery å®ä¾‹åç§°è°ƒæ•´ï¼‰ã€‚

- celery -A tasks.celery_app worker --loglevel=info -c 1
  äºŒã€ç¯å¢ƒå‡†å¤‡

1. åŸºç¡€ç¯å¢ƒè¦æ±‚

- Python 3.8+
- Redis 6.0+ï¼ˆæœ¬åœ°è¿è¡Œï¼Œé»˜è®¤ç«¯å£ 6379ï¼Œæ— éœ€é¢å¤–é…ç½®ï¼‰
- ä¾èµ–åŒ…å®‰è£…ï¼š
  pip install fastapi uvicorn celery redis requests

2. ä»£ç æ–‡ä»¶å‡†å¤‡
   å°†ä»¥ä¸‹ 3 ä¸ªæ–‡ä»¶æ”¾åœ¨åŒä¸€ç›®å½•ä¸‹ï¼š

ï¼ˆ1ï¼‰tasks.pyï¼ˆCelery ä»»åŠ¡å®šä¹‰ï¼‰

# tasks.py æœ€ç»ˆå¯è¿è¡Œç‰ˆæœ¬ï¼ˆå…¼å®¹ Windows+Celery 5.xï¼Œå…¨å±€ä¿¡å·å›è°ƒï¼‰

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(**file**)))

from celery import Celery
import requests
from datetime import datetime
from celery.signals import task_success, task_failure # å…¨å±€ä¿¡å·ä¾èµ–

# åˆå§‹åŒ– Celery

celery_app = Celery(
"task_queue",
broker="redis://localhost:6379/0",
backend="redis://localhost:6379/0",
timezone="Asia/Shanghai",
enable_utc=True
)

# Celery é…ç½®ï¼ˆWindows+å•è¿›ç¨‹é€‚é…ï¼‰

celery_app.conf.update(
task_serializer="json",
result_serializer="json",
accept_content=["json"],
worker_concurrency=1, # å•è¿›ç¨‹æ’é˜Ÿæ‰§è¡Œ
task_acks_late=True, # ä»»åŠ¡å®Œæˆåå†ç¡®è®¤
worker_prefetch_multiplier=1, # æ¯æ¬¡ä»…é¢„å– 1 ä¸ªä»»åŠ¡
result_expires=3600, # ç»“æœ 1 å°æ—¶åæ¸…ç†
worker_pool="solo", # Windows ä¸“ç”¨æ± ï¼Œé¿å…å…¼å®¹æ€§é—®é¢˜
task_reject_on_worker_lost=True # Worker ä¸¢å¤±æ—¶æ‹’ç»ä»»åŠ¡
)

# å›è°ƒæœåŠ¡åœ°å€ï¼ˆä¼˜å…ˆç”¨ 127.0.0.1ï¼Œé¿å… Windows localhost è§£æé—®é¢˜ï¼‰

CALLBACK_URL = "http://127.0.0.1:8001/receive-task-result"

def send_callback(task_id: str, status: str, result: dict = None, error: str = None):
"""é€šç”¨å›è°ƒå‡½æ•°ï¼ˆå¢åŠ è¯¦ç»†æ—¥å¿—ï¼Œä¾¿äºæ’æŸ¥ï¼‰"""
callback_data = {
"task_id": task_id,
"status": status,
"result": result,
"error": error,
"timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
} # æ‰“å°å‘é€æ—¥å¿—ï¼Œç¡®è®¤å›è°ƒè¯·æ±‚å·²è§¦å‘
print(f"\nğŸ“¤ å‡†å¤‡å‘é€å›è°ƒè¯·æ±‚ï¼š")
print(f" URL: {CALLBACK_URL}")
print(f" æ•°æ®: {callback_data}")

    try:
        response = requests.post(
            url=CALLBACK_URL,
            json=callback_data,
            headers={"Content-Type": "application/json"},
            timeout=10  # å»¶é•¿è¶…æ—¶ï¼Œé€‚é…Windowsç½‘ç»œ
        )
        # æ‰“å°å“åº”æ—¥å¿—ï¼Œç¡®è®¤å›è°ƒæœåŠ¡æ¥æ”¶æƒ…å†µ
        print(f"ğŸ“¥ å›è°ƒå“åº”ï¼šçŠ¶æ€ç ={response.status_code}ï¼Œå“åº”ä½“={response.text}")
        response.raise_for_status()  # è§¦å‘HTTPé”™è¯¯ï¼ˆå¦‚404/500ï¼‰
        print(f"âœ… ä»»åŠ¡ {task_id} å›è°ƒæˆåŠŸ")
    except requests.exceptions.ConnectionError:
        print(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ°å›è°ƒæœåŠ¡ï¼ˆè¯·æ£€æŸ¥8001ç«¯å£æ˜¯å¦å¯åŠ¨ï¼‰")
    except requests.exceptions.Timeout:
        print(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼šè¯·æ±‚è¶…æ—¶ï¼ˆå›è°ƒæœåŠ¡å“åº”è¿‡æ…¢ï¼‰")
    except Exception as e:
        print(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼š{str(e)}ï¼ˆç±»å‹ï¼š{type(e)}ï¼‰")

# å®šä¹‰æ ¸å¿ƒä¸šåŠ¡ä»»åŠ¡

@celery_app.task(bind=True, max_retries=0, ignore_result=False)
def process_task(self, task_id: str, data: dict):
"""æ ¸å¿ƒä¸šåŠ¡ä»»åŠ¡ï¼ˆ1 ç§’/ä»»åŠ¡ï¼Œæ’é˜Ÿæ‰§è¡Œï¼‰"""
try:
import time
print(f"\nğŸ”„ å¼€å§‹å¤„ç†ä»»åŠ¡ [ä¸šåŠ¡ ID: {task_id}]")
print(f" ä»»åŠ¡æ•°æ®: {data}")
time.sleep(1) # æ¨¡æ‹Ÿä¸šåŠ¡å¤„ç†è€—æ—¶

        # æ„é€ ä»»åŠ¡ç»“æœ
        task_result = {
            "status": "success",
            "business_task_id": task_id,
            "data": data,
            "message": "ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
            "process_time": 1.0
        }
        print(f"âœ… å®Œæˆå¤„ç†ä»»åŠ¡ [ä¸šåŠ¡ID: {task_id}]")
        return task_result

    except Exception as e:
        error_msg = str(e)
        print(f"\nâŒ å¤„ç†ä»»åŠ¡å¤±è´¥ [ä¸šåŠ¡ID: {task_id}]ï¼š{error_msg}")
        raise e  # æŠ›å‡ºå¼‚å¸¸ï¼Œè§¦å‘å¤±è´¥ä¿¡å·

# ========== å…¨å±€ä¿¡å·å›è°ƒï¼ˆæ ¸å¿ƒï¼šæ›¿ä»£åŸæœ‰ on_success ç»‘å®šï¼‰ ==========

@task_success.connect(sender=process_task)
def handle_task_success_signal(sender=None, result=None, \*\*kwargs):
"""ä»»åŠ¡æˆåŠŸå…¨å±€ä¿¡å·å›è°ƒï¼ˆç²¾å‡†ç»‘å®š process_task ä»»åŠ¡ï¼‰""" # ä¿®å¤ï¼šä» sender.request ä¸­è·å– Celery å†…éƒ¨ ID å’Œä¸šåŠ¡å‚æ•°
celery_task_id = sender.request.id # Celery å†…éƒ¨ä»»åŠ¡ ID
task_kwargs = sender.request.kwargs # ä»»åŠ¡æäº¤æ—¶çš„å…³é”®å­—å‚æ•°
business_task_id = task_kwargs.get("task_id") or celery_task_id

    print(f"\nğŸš€ å…¨å±€æˆåŠŸä¿¡å·è§¦å‘ [Celery ID: {celery_task_id}]")
    send_callback(
        task_id=business_task_id,
        status="success",
        result=result
    )

@task_failure.connect(sender=process_task)
def handle_task_failure_signal(sender=None, exception=None, \*\*kwargs):
"""ä»»åŠ¡å¤±è´¥å…¨å±€ä¿¡å·å›è°ƒ"""
celery_task_id = sender.request.id
task_kwargs = sender.request.kwargs
business_task_id = task_kwargs.get("task_id") or celery_task_id

    print(f"\nğŸš¨ å…¨å±€å¤±è´¥ä¿¡å·è§¦å‘ [Celery ID: {celery_task_id}]")
    send_callback(
        task_id=business_task_id,
        status="failed",
        error=str(exception)
    )

# æ¨¡å—åŠ è½½éªŒè¯ï¼ˆè¿è¡Œ tasks.py æ—¶æ‰§è¡Œï¼‰

if **name** == "**main**":
print("âœ… Celery ä»»åŠ¡æ¨¡å—åŠ è½½æˆåŠŸï¼æ— è¯­æ³•é”™è¯¯ï¼")
print(f"âœ… å›è°ƒæœåŠ¡åœ°å€ï¼š{CALLBACK_URL}")
print(f"âœ… Redis è¿æ¥åœ°å€ï¼šredis://localhost:6379/0")

ï¼ˆ2ï¼‰main_api.pyï¼ˆFastAPI ä¸»æœåŠ¡ï¼šä»»åŠ¡æäº¤/çŠ¶æ€æŸ¥è¯¢ï¼‰
from fastapi import FastAPI, HTTPException
from uuid import uuid4
from celery.result import AsyncResult
from typing import Optional
from tasks import process_task, celery_app

app = FastAPI(title="ä»»åŠ¡æäº¤æœåŠ¡")

@app.post("/submit-task")
async def submit_task(data: dict):
"""æ¥æ”¶ä»»åŠ¡æäº¤ï¼Œå­˜å…¥ Celery é˜Ÿåˆ—"""
try:
task_id = str(uuid4()) # ç”Ÿæˆä¸šåŠ¡å”¯ä¸€ä»»åŠ¡ ID
celery_task = process_task.delay(task_id=task_id, data=data)
return {
"code": 200,
"message": "ä»»åŠ¡å·²æäº¤è‡³é˜Ÿåˆ—",
"business_task_id": task_id,
"celery_task_id": celery_task.id
}
except Exception as e:
raise HTTPException(
status_code=500,
detail={"code": 500, "message": f"ä»»åŠ¡æäº¤å¤±è´¥ï¼š{str(e)}"}
)

@app.get("/task-status/{task_id}")
async def get_task_status(task_id: str):
"""æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ï¼ˆä»…æµ‹è¯•ç”¨ï¼‰"""
try: # æŸ¥æ‰¾ä¸šåŠ¡ ID å¯¹åº”çš„ Celery ä»»åŠ¡ ID
inspect = celery_app.control.inspect()
active_tasks = inspect.active() or {}
reserved_tasks = inspect.reserved() or {}
target_celery_id = None

        # æ£€æŸ¥æ´»è·ƒ/æ’é˜Ÿä»»åŠ¡
        for worker_tasks in list(active_tasks.values()) + list(reserved_tasks.values()):
            for task in worker_tasks:
                if task.get("kwargs", {}).get("task_id") == task_id:
                    target_celery_id = task.get("id")
                    break
            if target_celery_id:
                break

        if target_celery_id:
            async_result = AsyncResult(target_celery_id, app=celery_app)
            return {
                "code": 200,
                "business_task_id": task_id,
                "celery_task_id": target_celery_id,
                "status": async_result.state,
                "result": async_result.result if async_result.state == "SUCCESS" else None
            }
        else:
            raise HTTPException(status_code=404, detail={"code": 404, "message": "ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²å®Œæˆæ¸…ç†"})
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={"code": 500, "message": f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"}
        )

if **name** == "**main**":
import uvicorn
uvicorn.run(app, host="0.0.0.0", port=8000)

ï¼ˆ3ï¼‰callback_receiver.pyï¼ˆFastAPI å›è°ƒæœåŠ¡ï¼šæ¥æ”¶ä»»åŠ¡ç»“æœï¼‰
from fastapi import FastAPI, Request

app = FastAPI(title="ä»»åŠ¡å›è°ƒæ¥æ”¶æœåŠ¡")

@app.post("/receive-task-result")
async def receive_task_result(request: Request):
"""æ¥æ”¶ Celery ä»»åŠ¡å¤„ç†å®Œæˆåçš„å›è°ƒæ•°æ®"""
try:
data = await request.json()
print(f"ã€å›è°ƒæ¥æ”¶ã€‘ä»»åŠ¡ {data.get('task_id')}ï¼ŒçŠ¶æ€ï¼š{data.get('status')}ï¼Œæ•°æ®ï¼š{data}") # å¯æ‰©å±•ï¼šå°†å›è°ƒæ•°æ®å†™å…¥æ—¥å¿—/æ•°æ®åº“
return {
"code": 200,
"message": "å›è°ƒæ•°æ®å·²æ¥æ”¶",
"received_data": data
}
except Exception as e:
return {"code": 500, "message": f"å›è°ƒå¤„ç†å¤±è´¥ï¼š{str(e)}"}

if **name** == "**main**":
import uvicorn
uvicorn.run(app, host="0.0.0.0", port=8001)

ä¸‰ã€æµ‹è¯•æ­¥éª¤
æ­¥éª¤ 1ï¼šå¯åŠ¨åŸºç¡€æœåŠ¡ï¼ˆæŒ‰é¡ºåºæ‰§è¡Œï¼‰
1.1 å¯åŠ¨ Redis

- æœ¬åœ° Redis æ— éœ€é¢å¤–é…ç½®ï¼Œç›´æ¥å¯åŠ¨ï¼š

# Windowsï¼ˆRedis å®‰è£…ç›®å½•ä¸‹ï¼‰

redis-server.exe redis.windows.conf

# Linux/Mac

redis-server

- éªŒè¯ Redis å¯ç”¨ï¼šæ‰§è¡Œ redis-cli pingï¼Œè¿”å› PONG åˆ™æ­£å¸¸ã€‚
  1.2 å¯åŠ¨ FastAPI å›è°ƒæœåŠ¡
  æ‰“å¼€æ–°ç»ˆç«¯ï¼Œæ‰§è¡Œï¼š
  uvicorn callback_receiver:app --host 0.0.0.0 --port 8001
- æ—¥å¿—æ˜¾ç¤º Uvicorn running on http://0.0.0.0:8001 åˆ™å¯åŠ¨æˆåŠŸã€‚
  1.3 å¯åŠ¨ Celery Worker
  æ‰“å¼€æ–°ç»ˆç«¯ï¼Œè¿›å…¥ä»£ç ç›®å½•ï¼Œæ‰§è¡Œï¼š
  celery -A tasks.celery_app worker --loglevel=info -c 1 #linux
  python -m celery -A tasks.celery_app worker --loglevel=info -c 1 # windows
- å…³é”®æ—¥å¿—ï¼šcelery@xxx ready. ä¸” concurrency: 1ï¼ˆç¡®è®¤å•è¿›ç¨‹ï¼‰ï¼Œå¯åŠ¨æˆåŠŸã€‚
  1.4 å¯åŠ¨ FastAPI ä¸»æœåŠ¡
  æ‰“å¼€æ–°ç»ˆç«¯ï¼Œæ‰§è¡Œï¼š
  uvicorn main_api:app --host 0.0.0.0 --port 8000
- æ—¥å¿—æ˜¾ç¤º Uvicorn running on http://0.0.0.0:8000 åˆ™å¯åŠ¨æˆåŠŸã€‚
  æ­¥éª¤ 2ï¼šæ‰¹é‡æäº¤ 1000 ä¸ªä»»åŠ¡
  åˆ›å»ºæµ‹è¯•è„šæœ¬ test_batch_submit.pyï¼ŒçŸ­æ—¶é—´å†…å‘ä¸»æœåŠ¡æäº¤ 1000 ä¸ªä»»åŠ¡ï¼š
  import requests
  import time
  import threading

# ç›®æ ‡æ¥å£åœ°å€

API_URL = "http://localhost:8000/submit-task"

# æ€»ä»»åŠ¡æ•°

TOTAL_TASKS = 1000

# è®°å½•æäº¤æˆåŠŸ/å¤±è´¥çš„ä»»åŠ¡

success_tasks = []
failed_tasks = []

def submit_task(task_index):
"""å•ä»»åŠ¡æäº¤å‡½æ•°"""
try: # æ„é€ ä»»åŠ¡æ•°æ®ï¼ˆåŒ…å«ä»»åŠ¡åºå·ï¼Œä¾¿äºè¿½è¸ªï¼‰
task_data = {"task_index": task_index, "content": f"æµ‹è¯•ä»»åŠ¡{task_index}"}
response = requests.post(
API_URL,
json=task_data,
timeout=10
)
if response.status_code == 200:
result = response.json()
success_tasks.append({
"task_index": task_index,
"business_task_id": result["business_task_id"],
"celery_task_id": result["celery_task_id"]
})
print(f"æäº¤ä»»åŠ¡{task_index}æˆåŠŸï¼š{result['business_task_id']}")
else:
failed_tasks.append({"task_index": task_index, "error": f"çŠ¶æ€ç ï¼š{response.status_code}"})
print(f"æäº¤ä»»åŠ¡{task_index}å¤±è´¥ï¼šçŠ¶æ€ç {response.status_code}")
except Exception as e:
failed_tasks.append({"task_index": task_index, "error": str(e)})
print(f"æäº¤ä»»åŠ¡{task_index}å¤±è´¥ï¼š{str(e)}")

if **name** == "**main**":
start_time = time.time() # å¤šçº¿ç¨‹æäº¤ï¼ˆçŸ­æ—¶é—´å†…å®Œæˆ 1000 æ¬¡è¯·æ±‚ï¼‰
threads = []
for i in range(TOTAL_TASKS):
t = threading.Thread(target=submit_task, args=(i+1,))
threads.append(t)
t.start() # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
for t in threads:
t.join() # è¾“å‡ºæäº¤ç»Ÿè®¡
end_time = time.time()
print("\n===== ä»»åŠ¡æäº¤ç»Ÿè®¡ =====")
print(f"æ€»æäº¤ä»»åŠ¡æ•°ï¼š{TOTAL_TASKS}")
print(f"æäº¤æˆåŠŸæ•°ï¼š{len(success_tasks)}")
print(f"æäº¤å¤±è´¥æ•°ï¼š{len(failed_tasks)}")
print(f"æ€»è€—æ—¶ï¼š{end_time - start_time:.2f}ç§’") # å¯é€‰ï¼šå°†æˆåŠŸä»»åŠ¡ ID å†™å…¥æ–‡ä»¶ï¼Œä¾¿äºåç»­æ ¸å¯¹
with open("submitted_tasks.txt", "w", encoding="utf-8") as f:
for task in success_tasks:
f.write(f"{task['task_index']},{task['business_task_id']},{task['celery_task_id']}\n")

æ‰§è¡Œæµ‹è¯•è„šæœ¬ï¼Œæ‰¹é‡æäº¤ä»»åŠ¡ï¼š
python test_batch_submit.py

- é¢„æœŸç»“æœï¼š1000 ä¸ªä»»åŠ¡åœ¨å‡ ç§’å†…æäº¤å®Œæˆï¼Œsuccess_tasks æ•°é‡æ¥è¿‘ 1000ï¼ˆå°‘é‡å¤±è´¥å¯å¿½ç•¥ï¼Œç½‘ç»œæ³¢åŠ¨å¯¼è‡´ï¼‰ã€‚
  (px_ri_project) PS D:\Project\gitee\research-institute-project\app\tests\test_celery> python .\test_batch_submit.py
  æäº¤ä»»åŠ¡ 6 æˆåŠŸï¼š216b3ed0-9df1-4ddf-aeb9-1d678bc882a2
  æäº¤ä»»åŠ¡ 3 æˆåŠŸï¼ša66f7202-0969-4bf6-a0d2-66e77c47aab3
  æäº¤ä»»åŠ¡ 31 æˆåŠŸï¼šba7fd324-a923-4b09-8524-bf5511daa936
  æäº¤ä»»åŠ¡ 32 æˆåŠŸï¼š3b3741b4-0bc1-42a0-8022-a242d28c1cc3
  æäº¤ä»»åŠ¡ 28 æˆåŠŸï¼šd3a82c23-e756-4798-9da1-1c7db269f553
  ...
  æäº¤ä»»åŠ¡ 539 æˆåŠŸï¼š4bf83687-29a3-4733-b548-e0ef6d04a517
  æäº¤ä»»åŠ¡ 632 æˆåŠŸï¼š6c35cb61-8917-40bf-8ab6-6bda36e01279
  æäº¤ä»»åŠ¡ 587 æˆåŠŸï¼ša8c56801-685a-4712-a810-6236288577a8
  æäº¤ä»»åŠ¡ 596 æˆåŠŸï¼šf83a3a36-aba4-4443-a6df-34dddcf78ee7
  æäº¤ä»»åŠ¡ 604 æˆåŠŸï¼š4ab7120f-7f8c-4e46-8cd6-d6ff0d7e0ccb

===== ä»»åŠ¡æäº¤ç»Ÿè®¡ =====
æ€»æäº¤ä»»åŠ¡æ•°ï¼š1000
æäº¤æˆåŠŸæ•°ï¼š1000
æäº¤å¤±è´¥æ•°ï¼š0
æ€»è€—æ—¶ï¼š5.19 ç§’
æ­¥éª¤ 3ï¼šéªŒè¯ä»»åŠ¡å¤„ç†ä¸å›è°ƒ
3.1 éªŒè¯ Celery ä»»åŠ¡æ’é˜Ÿæ‰§è¡Œ
æŸ¥çœ‹ Celery Worker ç»ˆç«¯æ—¥å¿—ï¼š

- æ—¥å¿—æŒ‰é¡ºåºæ˜¾ç¤º å®Œæˆä»»åŠ¡ xxxï¼Œæ¯ç§’å¤„ç† 1 ä¸ªä»»åŠ¡ï¼ˆå›  time.sleep(1)ï¼‰ï¼›
- æ— å¹¶å‘æ‰§è¡Œæ—¥å¿—ï¼ˆç¡®è®¤å•è¿›ç¨‹æ’é˜Ÿï¼‰ï¼›
- æ¯ä¸ªä»»åŠ¡å®Œæˆåæ˜¾ç¤º ä»»åŠ¡ xxx å›è°ƒæˆåŠŸã€‚
  [2025-12-19 12:44:00,104: INFO/MainProcess] Task tasks.process_task[c3c002ad-73b9-43c6-8393-21a5ad38ab10] received
  [2025-12-19 12:44:00,105: WARNING/MainProcess]
  ğŸ”„ å¼€å§‹å¤„ç†ä»»åŠ¡ [ä¸šåŠ¡ ID: 0d9793a1-9c53-4d6e-90bb-ee591fc787b0]
  [2025-12-19 12:44:00,105: WARNING/MainProcess] ä»»åŠ¡æ•°æ®: {'task_index': 640, 'content': 'æµ‹è¯•ä»»åŠ¡ 640'}
  [2025-12-19 12:44:01,107: WARNING/MainProcess] âœ… å®Œæˆå¤„ç†ä»»åŠ¡ [ä¸šåŠ¡ ID: 0d9793a1-9c53-4d6e-90bb-ee591fc787b0]
  [2025-12-19 12:44:01,108: WARNING/MainProcess]
  ğŸš€ å…¨å±€æˆåŠŸä¿¡å·è§¦å‘ [Celery ID: c3c002ad-73b9-43c6-8393-21a5ad38ab10]
  [2025-12-19 12:44:01,108: WARNING/MainProcess]
  ğŸ“¤ å‡†å¤‡å‘é€å›è°ƒè¯·æ±‚ï¼š
  [2025-12-19 12:44:01,108: WARNING/MainProcess] URL: http://127.0.0.1:8001/receive-task-result
  [2025-12-19 12:44:01,109: WARNING/MainProcess] æ•°æ®: {'task_id': '0d9793a1-9c53-4d6e-90bb-ee591fc787b0', 'status': 'success', 'result': {'status': 'success', 'business_task_id': '0d9793a1-9c53-4d6e-90bb-ee591fc787b0', 'data': {'task_index': 640, 'content': 'æµ‹è¯•ä»»åŠ¡ 640'}, 'message': 'ä»»åŠ¡æ‰§è¡Œå®Œæˆ', 'process_time': 1.0}, 'error': None, 'timestamp': '2025-12-19 12:44:01'}
  [2025-12-19 12:44:01,127: WARNING/MainProcess] ğŸ“¥ å›è°ƒå“åº”ï¼šçŠ¶æ€ç =200ï¼Œå“åº”ä½“={"code":200,"message":"å›è°ƒæ•°æ®å·²æ¥æ”¶","received_data":{"task_id":"0d9793a1-9c53-4d6e-90bb-ee591fc787b0","status":"success","result":{"status":"success","business_task_id":"0d9793a1-9c53-4d6e-90bb-ee591fc787b0","data":{"task_index":640,"content":"æµ‹è¯•ä»»
  åŠ¡ 640"},"message":"ä»»åŠ¡æ‰§è¡Œå®Œæˆ","process_time":1.0},"error":null,"timestamp":"2025-12-19 12:44:01"}}
  3.2 éªŒè¯å›è°ƒæœåŠ¡æ¥æ”¶æ•°æ®
  æŸ¥çœ‹å›è°ƒæœåŠ¡ç»ˆç«¯æ—¥å¿—ï¼š
- æŒç»­æ˜¾ç¤º ã€å›è°ƒæ¥æ”¶ã€‘ä»»åŠ¡ xxxï¼ŒçŠ¶æ€ï¼šsuccessï¼›
- å›è°ƒæ•°æ®åŒ…å« task_idã€statusã€result ç­‰å­—æ®µï¼Œä¸ä»»åŠ¡ä¸€ä¸€å¯¹åº”ã€‚
  ã€å›è°ƒæ¥æ”¶ã€‘ä»»åŠ¡ 65cb0842-ac52-47fa-86f4-9bb8be00e391ï¼ŒçŠ¶æ€ï¼šsuccessï¼Œæ•°æ®ï¼š{'task_id': '65cb0842-ac52-47fa-86f4-9bb8be00e391', 'status': 'success', 'result': {'status': 'success', 'business_task_id': '65cb0842-ac52-47fa-86f4-9bb8be00e391', 'data': {'task_index': 676, 'content': 'æµ‹è¯•ä»»åŠ¡ 676'}, 'message': 'ä»»åŠ¡æ‰§è¡Œå®Œæˆ', 'process_time': 1.0}, 'error': None, 'timestamp': '2025-12-19 12:44:17'}
  INFO: 127.0.0.1:50586 - "POST /receive-task-result HTTP/1.1" 200 OK
  3.3 æ ¸å¯¹ä»»åŠ¡å¤„ç†å®Œæ•´æ€§ï¼ˆå¯é€‰ï¼‰
- ç»Ÿè®¡ Celery Worker æ—¥å¿—ä¸­ å®Œæˆä»»åŠ¡ çš„æ•°é‡ï¼Œåº”ä¸æäº¤æˆåŠŸæ•°ä¸€è‡´ï¼›
- ç»Ÿè®¡å›è°ƒæœåŠ¡æ—¥å¿—ä¸­ å›è°ƒæ¥æ”¶ çš„æ•°é‡ï¼Œåº”ä¸å¤„ç†å®Œæˆæ•°ä¸€è‡´ï¼›
- å¯é€šè¿‡ submitted_tasks.txt ä¸­çš„ business_task_idï¼Œè°ƒç”¨ /task-status/{task_id} æ¥å£éªŒè¯å•ä¸ªä»»åŠ¡çŠ¶æ€ã€‚
  å››ã€é¢„æœŸç»“æœ

1. ä»»åŠ¡æäº¤ï¼š1000 ä¸ªä»»åŠ¡åœ¨å‡ ç§’å†…æäº¤å®Œæˆï¼ŒæˆåŠŸæ•° â‰¥ 990ï¼ˆç½‘ç»œæ­£å¸¸æƒ…å†µä¸‹ï¼‰ï¼›
2. ä»»åŠ¡å¤„ç†ï¼šCelery ä»¥å•è¿›ç¨‹ä¾æ¬¡å¤„ç†ä»»åŠ¡ï¼Œæ¯ç§’å®Œæˆ 1 ä¸ªï¼Œæ€»å¤„ç†è€—æ—¶çº¦ 1000 ç§’ï¼ˆç¬¦åˆæ’é˜Ÿé€»è¾‘ï¼‰ï¼›
3. å›è°ƒéªŒè¯ï¼šæ‰€æœ‰å¤„ç†å®Œæˆçš„ä»»åŠ¡ï¼Œå‡å‘å›è°ƒæœåŠ¡å‘é€äº†å›è°ƒæ•°æ®ï¼Œå›è°ƒæˆåŠŸç‡ 100%ï¼ˆç½‘ç»œæ­£å¸¸æƒ…å†µä¸‹ï¼‰ï¼›
4. æ•°æ®ä¸€è‡´æ€§ï¼šæäº¤æˆåŠŸçš„ä»»åŠ¡æ•° = Celery å¤„ç†å®Œæˆæ•° = å›è°ƒæœåŠ¡æ¥æ”¶æ•°ã€‚
   äº”ã€å¸¸è§é—®é¢˜æ’æŸ¥
   é—®é¢˜ç°è±¡
   æ’æŸ¥æ–¹å‘
   ä»»åŠ¡æäº¤å¤±è´¥ç‡é«˜
5. ä¸»æœåŠ¡ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼›2. Redis æ˜¯å¦æ­£å¸¸è¿è¡Œï¼›3. æäº¤çº¿ç¨‹æ•°è¿‡å¤šå¯¼è‡´ç«¯å£è€—å°½ï¼ˆå¯å‡å°‘çº¿ç¨‹æ•°ï¼‰
   Celery æœªå¤„ç†ä»»åŠ¡
6. Broker åœ°å€æ˜¯å¦æ­£ç¡®ï¼ˆredis://localhost:6379/0ï¼‰ï¼›2. Worker æ˜¯å¦å¯åŠ¨ï¼ˆcelery -A tasks.celery_app workerï¼‰
   ä»»åŠ¡å¹¶å‘æ‰§è¡Œï¼ˆæœªæ’é˜Ÿï¼‰
   æ£€æŸ¥ Celery é…ç½®ï¼šworker_concurrency=1 å’Œ worker_prefetch_multiplier=1 æ˜¯å¦ç”Ÿæ•ˆ
   å›è°ƒå¤±è´¥
7. å›è°ƒæœåŠ¡æ˜¯å¦å¯åŠ¨ï¼ˆç«¯å£ 8001ï¼‰ï¼›2. CALLBACK_URL æ˜¯å¦æ­£ç¡®ï¼›3. å›è°ƒæœåŠ¡æ˜¯å¦èƒ½è¢« Celery è®¿é—®
   ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢ä¸åˆ°
8. ä»»åŠ¡æ˜¯å¦å·²å®Œæˆå¹¶è¢«æ¸…ç†ï¼ˆresult_expires=3600ï¼Œ1 å°æ—¶åæ¸…ç†ï¼‰ï¼›2. ä¸šåŠ¡ ID ä¸ Celery ID æ˜ å°„æ˜¯å¦æ­£ç¡®

å…­ã€æ‰©å±•è¯´æ˜

1. æ€§èƒ½è°ƒä¼˜ï¼šè‹¥éœ€æé«˜å¤„ç†é€Ÿåº¦ï¼Œå¯è°ƒæ•´ worker_concurrencyï¼ˆå¦‚æ”¹ä¸º 10ï¼ŒåŒæ—¶è°ƒæ•´ worker_prefetch_multiplier=10ï¼‰ï¼Œä»ä¿æŒæ’é˜Ÿä½†æå‡å¹¶å‘åº¦ï¼›
2. æ•°æ®æŒä¹…åŒ–ï¼šå¯åœ¨å›è°ƒæœåŠ¡ä¸­æ·»åŠ æ•°æ®åº“å†™å…¥é€»è¾‘ï¼Œå°†å›è°ƒæ•°æ®å­˜å…¥ MySQL/PostgreSQLï¼Œä¾¿äºåç»­ç»Ÿè®¡ï¼›
3. ç›‘æ§å‘Šè­¦ï¼šå¯é€šè¿‡ Redis ç›‘æ§é˜Ÿåˆ—é•¿åº¦ï¼ˆLLEN celeryï¼‰ï¼Œè‹¥é˜Ÿåˆ—å †ç§¯è¿‡å¤šï¼ŒåŠæ—¶å‘Šè­¦ï¼›
4. å¼‚å¸¸é‡è¯•ï¼šè‹¥éœ€ä»»åŠ¡å¤±è´¥é‡è¯•ï¼Œå¯ä¿®æ”¹ max_retriesï¼ˆå¦‚ max_retries=3ï¼‰ï¼Œå¹¶è®¾ç½®é‡è¯•é—´éš”ï¼šself.retry(exc=e, countdown=5)ã€‚
