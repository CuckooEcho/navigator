import sys
import os
import logging
from logging.handlers import RotatingFileHandler
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from celery import Celery
import requests
from datetime import datetime
from celery.signals import task_success, task_failure

# ===================== æ—¥å¿—é…ç½®ï¼ˆLinux ç”Ÿäº§çº§ï¼‰=====================
# æ—¥å¿—å­˜å‚¨è·¯å¾„ï¼ˆLinux å»ºè®®æ”¾åœ¨ /var/log æˆ–é¡¹ç›®ç›®å½•ï¼‰
LOG_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "logs")
os.makedirs(LOG_DIR, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºæ—¥å¿—ç›®å½•

# æ—¥å¿—æ ¼å¼
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(process)d - %(filename)s:%(lineno)d - %(message)s"
DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

# åˆå§‹åŒ–logger
logger = logging.getLogger("celery_task")
logger.setLevel(logging.INFO)  # æ—¥å¿—çº§åˆ«ï¼šDEBUG/INFO/WARNING/ERROR/CRITICAL

# 1. æ§åˆ¶å°å¤„ç†å™¨ï¼ˆå®æ—¶æŸ¥çœ‹ï¼‰
console_handler = logging.StreamHandler()
console_handler.setFormatter(logging.Formatter(LOG_FORMAT, DATE_FORMAT))
console_handler.setLevel(logging.INFO)

# 2. æ–‡ä»¶å¤„ç†å™¨ï¼ˆæŒ‰å¤§å°è½®è½¬ï¼Œé¿å…æ—¥å¿—æ–‡ä»¶è¿‡å¤§ï¼‰
file_handler = RotatingFileHandler(
    filename=os.path.join(LOG_DIR, "celery_task.log"),
    maxBytes=10 * 1024 * 1024,  # å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§10MB
    backupCount=5,  # æœ€å¤šä¿ç•™5ä¸ªå¤‡ä»½æ–‡ä»¶
    encoding="utf-8"
)
file_handler.setFormatter(logging.Formatter(LOG_FORMAT, DATE_FORMAT))
file_handler.setLevel(logging.INFO)

# é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
if not logger.handlers:
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

# ===================== Celery åˆå§‹åŒ– =====================
celery_app = Celery(
    "task_queue",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/0",
    timezone="Asia/Shanghai",
    enable_utc=True
)

# Celeryé…ç½®ï¼ˆLinux é€‚é…ç‰ˆï¼‰
# Celeryé…ç½®ï¼ˆLinux é€‚é…ç‰ˆï¼Œé’ˆå¯¹å¤§æ¨¡å‹ä½å¹¶å‘/é•¿è€—æ—¶ä»»åŠ¡ä¼˜åŒ–ï¼‰
celery_app.conf.update(
    # ========== åºåˆ—åŒ–é…ç½® ==========
    # ä»»åŠ¡åºåˆ—åŒ–æ ¼å¼ï¼šä½¿ç”¨JSONï¼ˆè·¨è¯­è¨€å…¼å®¹ã€è½»é‡ï¼Œé¿å…pickleå®‰å…¨é£é™©ï¼‰
    task_serializer="json",
    # ä»»åŠ¡ç»“æœåºåˆ—åŒ–æ ¼å¼ï¼šä¸ä»»åŠ¡åºåˆ—åŒ–ä¿æŒä¸€è‡´ï¼Œç¡®ä¿ç»“æœè§£ææ— å…¼å®¹é—®é¢˜
    result_serializer="json",
    # å…è®¸æ¥æ”¶çš„å†…å®¹ç±»å‹ï¼šä»…æ¥æ”¶JSONæ ¼å¼ï¼Œè¿‡æ»¤éæ³•è¯·æ±‚ï¼Œæå‡å®‰å…¨æ€§
    accept_content=["json"],

    # ========== å¹¶å‘æ§åˆ¶ï¼ˆæ ¸å¿ƒï¼šé€‚é…å¤§æ¨¡å‹ä½å¹¶å‘ç‰¹æ€§ï¼‰ ==========
    # Workerå¹¶å‘æ•°ï¼šLinuxå¤šæ ¸ç¯å¢ƒä¸‹è®¾ä¸º2ï¼ˆå¯æŒ‰CPUæ ¸å¿ƒæ•°è°ƒæ•´ï¼Œå¦‚4/8ï¼‰
    # å–å€¼åŸå› ï¼šå¤§æ¨¡å‹æ¨ç†æ˜¯è®¡ç®—å¯†é›†å‹ä»»åŠ¡ï¼Œå¹¶å‘è¿‡é«˜ä¼šå¯¼è‡´CPU/GPUèµ„æºè€—å°½ï¼Œè§¦å‘è¶…æ—¶
    worker_concurrency=2,         

    # ========== ä»»åŠ¡ç¡®è®¤æœºåˆ¶ï¼ˆé¿å…ä»»åŠ¡ä¸¢å¤±ï¼‰ ==========
    # ä»»åŠ¡å»¶è¿Ÿç¡®è®¤ï¼šWorkeræ‰§è¡Œå®Œä»»åŠ¡åå†å‘Brokerç¡®è®¤ä»»åŠ¡å®Œæˆ
    # ä½œç”¨ï¼šè‹¥Workeræ‰§è¡Œä¸­å´©æºƒï¼ŒBrokerä¼šå°†ä»»åŠ¡é‡æ–°åˆ†å‘ç»™å…¶ä»–Workerï¼Œé¿å…ä»»åŠ¡ä¸¢å¤±
    task_acks_late=True,

    # ========== ä»»åŠ¡é¢„å–æ§åˆ¶ï¼ˆé¿å…å †ç§¯ï¼‰ ==========
    # Workeré¢„å–ä»»åŠ¡æ•°ï¼šæ¯æ¬¡ä»…ä»Brokeré¢„å–1ä¸ªä»»åŠ¡
    # å–å€¼åŸå› ï¼šå¤§æ¨¡å‹ä»»åŠ¡è€—æ—¶æé•¿ï¼ˆåˆ†é’Ÿ/å°æ—¶çº§ï¼‰ï¼Œé¢„å–è¿‡å¤šä¼šå¯¼è‡´ä»»åŠ¡å †ç§¯åœ¨Workeræœ¬åœ°ï¼Œæ— æ³•è¢«å…¶ä»–Workerè°ƒåº¦
    worker_prefetch_multiplier=1,

    # ========== ç»“æœå­˜å‚¨é…ç½® ==========
    # ä»»åŠ¡ç»“æœè¿‡æœŸæ—¶é—´ï¼š3600ç§’ï¼ˆ1å°æ—¶ï¼‰
    # ä½œç”¨ï¼šé¿å…Redisä¸­ç§¯å‹å¤§é‡è¿‡æœŸç»“æœï¼Œå ç”¨å†…å­˜ï¼›å¤§æ¨¡å‹ä»»åŠ¡ç»“æœæ— éœ€é•¿æœŸå­˜å‚¨ï¼Œ1å°æ—¶è¶³å¤Ÿä¸šåŠ¡å›è°ƒå¤„ç†
    result_expires=3600,

    # ========== å¼‚å¸¸å®¹é”™é…ç½® ==========
    # Workerä¸¢å¤±æ—¶æ‹’ç»ä»»åŠ¡ï¼šè‹¥Workerè¿›ç¨‹æ„å¤–ç»ˆæ­¢ï¼ˆå¦‚OOMã€å´©æºƒï¼‰ï¼ŒBrokerä¼šæ‹’ç»è¯¥Workeræœªå®Œæˆçš„ä»»åŠ¡
    # ä½œç”¨ï¼šé˜²æ­¢æ— æ•ˆä»»åŠ¡å ç”¨é˜Ÿåˆ—ï¼Œç¡®ä¿ä»»åŠ¡é‡æ–°åˆ†å‘åˆ°å¥åº·çš„Worker
    task_reject_on_worker_lost=True,

    # ========== æ—¥å¿—æ ¼å¼åŒ–é…ç½® ==========
    # Workerè¿›ç¨‹æ—¥å¿—æ ¼å¼ï¼šä½¿ç”¨è‡ªå®šä¹‰çš„LOG_FORMATï¼ˆåŒ…å«æ—¶é—´/è¿›ç¨‹ID/æ–‡ä»¶è¡Œå·ï¼Œä¾¿äºå®šä½é—®é¢˜ï¼‰
    worker_log_format=LOG_FORMAT,
    # ä»»åŠ¡æ‰§è¡Œæ—¥å¿—æ ¼å¼ï¼šä¸Workeræ—¥å¿—æ ¼å¼ç»Ÿä¸€ï¼Œç¡®ä¿ä»»åŠ¡å…¨ç”Ÿå‘½å‘¨æœŸæ—¥å¿—æ ¼å¼ä¸€è‡´
    worker_task_log_format=LOG_FORMAT
)

# å›è°ƒæœåŠ¡åœ°å€
CALLBACK_URL = "http://127.0.0.1:8001/receive-task-result"

def send_callback(task_id: str, status: str, result: dict = None, error: str = None):
    """é€šç”¨å›è°ƒå‡½æ•°ï¼ˆæ—¥å¿—ç‰ˆï¼‰"""
    callback_data = {
        "task_id": task_id,
        "status": status,
        "result": result,
        "error": error,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    logger.info(f"å‡†å¤‡å‘é€å›è°ƒè¯·æ±‚ | URL: {CALLBACK_URL} | æ•°æ®: {callback_data}")
    try:
        response = requests.post(
            url=CALLBACK_URL,
            json=callback_data,
            headers={"Content-Type": "application/json"},
            timeout=10
        )
        logger.info(f"å›è°ƒå“åº” | ä»»åŠ¡ID: {task_id} | çŠ¶æ€ç : {response.status_code} | å“åº”ä½“: {response.text}")
        response.raise_for_status()
        logger.info(f"âœ… ä»»åŠ¡ {task_id} å›è°ƒæˆåŠŸ")
    except requests.exceptions.ConnectionError:
        logger.error(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ°å›è°ƒæœåŠ¡ï¼ˆ8001ç«¯å£æœªå¯åŠ¨ï¼Ÿï¼‰")
    except requests.exceptions.Timeout:
        logger.error(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼šè¯·æ±‚è¶…æ—¶ï¼ˆå›è°ƒæœåŠ¡å“åº”è¿‡æ…¢ï¼‰")
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼š{str(e)} | å¼‚å¸¸ç±»å‹: {type(e)}", exc_info=True)

# ===================== æ ¸å¿ƒä¸šåŠ¡ä»»åŠ¡ =====================
@celery_app.task(bind=True, max_retries=0, ignore_result=False)
def process_task(self, task_id: str, data: dict):
    """æ ¸å¿ƒä¸šåŠ¡ä»»åŠ¡ï¼ˆæ—¥å¿—ç‰ˆï¼‰"""
    try:
        import time
        logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†ä»»åŠ¡ | ä¸šåŠ¡ID: {task_id} | ä»»åŠ¡æ•°æ®: {data}")
        time.sleep(1)  # æ¨¡æ‹Ÿä¸šåŠ¡å¤„ç†è€—æ—¶
        
        task_result = {
            "status": "success",
            "business_task_id": task_id,
            "data": data,
            "message": "ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
            "process_time": 1.0
        }
        logger.info(f"âœ… å®Œæˆå¤„ç†ä»»åŠ¡ | ä¸šåŠ¡ID: {task_id}")
        return task_result
    
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ å¤„ç†ä»»åŠ¡å¤±è´¥ | ä¸šåŠ¡ID: {task_id} | é”™è¯¯ä¿¡æ¯: {error_msg}", exc_info=True)
        raise e

# ===================== å…¨å±€ä¿¡å·å›è°ƒ =====================
@task_success.connect(sender=process_task)
def handle_task_success_signal(sender=None, result=None, **kwargs):
    """ä»»åŠ¡æˆåŠŸå…¨å±€ä¿¡å·å›è°ƒ"""
    celery_task_id = sender.request.id
    task_kwargs = sender.request.kwargs
    business_task_id = task_kwargs.get("task_id") or celery_task_id
    
    logger.info(f"ğŸš€ å…¨å±€æˆåŠŸä¿¡å·è§¦å‘ | Celery ID: {celery_task_id} | ä¸šåŠ¡ID: {business_task_id}")
    send_callback(
        task_id=business_task_id,
        status="success",
        result=result
    )

@task_failure.connect(sender=process_task)
def handle_task_failure_signal(sender=None, exception=None, **kwargs):
    """ä»»åŠ¡å¤±è´¥å…¨å±€ä¿¡å·å›è°ƒ"""
    celery_task_id = sender.request.id
    task_kwargs = sender.request.kwargs
    business_task_id = task_kwargs.get("task_id") or celery_task_id
    
    logger.error(f"ğŸš¨ å…¨å±€å¤±è´¥ä¿¡å·è§¦å‘ | Celery ID: {celery_task_id} | ä¸šåŠ¡ID: {business_task_id} | å¼‚å¸¸: {str(exception)}")
    send_callback(
        task_id=business_task_id,
        status="failed",
        error=str(exception)
    )

# ===================== æ¨¡å—åŠ è½½éªŒè¯ =====================
if __name__ == "__main__":
    logger.info("âœ… Celeryä»»åŠ¡æ¨¡å—åŠ è½½æˆåŠŸï¼æ— è¯­æ³•é”™è¯¯ï¼")
    logger.info(f"âœ… å›è°ƒæœåŠ¡åœ°å€ï¼š{CALLBACK_URL}")
    logger.info(f"âœ… Redisè¿æ¥åœ°å€ï¼šredis://localhost:6379/0")
    logger.info(f"âœ… é€‚é…ç³»ç»Ÿï¼šLinuxï¼ˆCeleryæ± ç±»å‹ï¼špreforkï¼‰")
    logger.info(f"âœ… æ—¥å¿—å­˜å‚¨è·¯å¾„ï¼š{LOG_DIR}")