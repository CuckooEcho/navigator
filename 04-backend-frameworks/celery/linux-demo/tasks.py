import sys
import os
import logging
from logging.handlers import RotatingFileHandler
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from celery import Celery
import requests
from datetime import datetime
from celery.signals import task_success, task_failure

# ===================== æ—¥å¿—é…ç½®ï¼ˆLinux ç”Ÿäº§çº§ï¼‰=====================
# æ—¥å¿—å­˜å‚¨è·¯å¾„ï¼ˆLinux å»ºè®®æ”¾åœ¨ /var/log æˆ–é¡¹ç›®ç›®å½•ï¼‰
LOG_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "logs")
os.makedirs(LOG_DIR, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºæ—¥å¿—ç›®å½•

# æ—¥å¿—æ ¼å¼
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(process)d - %(filename)s:%(lineno)d - %(message)s"
DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

# åˆå§‹åŒ–logger
logger = logging.getLogger("celery_task")
logger.setLevel(logging.INFO)  # æ—¥å¿—çº§åˆ«ï¼šDEBUG/INFO/WARNING/ERROR/CRITICAL

# 1. æ§åˆ¶å°å¤„ç†å™¨ï¼ˆå®æ—¶æŸ¥çœ‹ï¼‰
console_handler = logging.StreamHandler()
console_handler.setFormatter(logging.Formatter(LOG_FORMAT, DATE_FORMAT))
console_handler.setLevel(logging.INFO)

# 2. æ–‡ä»¶å¤„ç†å™¨ï¼ˆæŒ‰å¤§å°è½®è½¬ï¼Œé¿å…æ—¥å¿—æ–‡ä»¶è¿‡å¤§ï¼‰
file_handler = RotatingFileHandler(
    filename=os.path.join(LOG_DIR, "celery_task.log"),
    maxBytes=10 * 1024 * 1024,  # å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§10MB
    backupCount=5,  # æœ€å¤šä¿ç•™5ä¸ªå¤‡ä»½æ–‡ä»¶
    encoding="utf-8"
)
file_handler.setFormatter(logging.Formatter(LOG_FORMAT, DATE_FORMAT))
file_handler.setLevel(logging.INFO)

# é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
if not logger.handlers:
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

# ===================== Celery åˆå§‹åŒ– =====================
celery_app = Celery(
    "task_queue",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/0",
    timezone="Asia/Shanghai",
    enable_utc=True
)

# Celeryé…ç½®ï¼ˆLinux é€‚é…ç‰ˆï¼‰
celery_app.conf.update(
    task_serializer="json",
    result_serializer="json",
    accept_content=["json"],
    worker_concurrency=2,          # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´ï¼ˆå¦‚4/8ï¼‰
    task_acks_late=True,
    worker_prefetch_multiplier=1,
    result_expires=3600,
    task_reject_on_worker_lost=True,
    # å¼€å¯Celeryè‡ªèº«æ—¥å¿—ï¼ˆä¸è‡ªå®šä¹‰æ—¥å¿—äº’è¡¥ï¼‰
    worker_log_format=LOG_FORMAT,
    worker_task_log_format=LOG_FORMAT
)

# å›è°ƒæœåŠ¡åœ°å€
CALLBACK_URL = "http://127.0.0.1:8001/receive-task-result"

def send_callback(task_id: str, status: str, result: dict = None, error: str = None):
    """é€šç”¨å›è°ƒå‡½æ•°ï¼ˆæ—¥å¿—ç‰ˆï¼‰"""
    callback_data = {
        "task_id": task_id,
        "status": status,
        "result": result,
        "error": error,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    logger.info(f"å‡†å¤‡å‘é€å›è°ƒè¯·æ±‚ | URL: {CALLBACK_URL} | æ•°æ®: {callback_data}")
    try:
        response = requests.post(
            url=CALLBACK_URL,
            json=callback_data,
            headers={"Content-Type": "application/json"},
            timeout=10
        )
        logger.info(f"å›è°ƒå“åº” | ä»»åŠ¡ID: {task_id} | çŠ¶æ€ç : {response.status_code} | å“åº”ä½“: {response.text}")
        response.raise_for_status()
        logger.info(f"âœ… ä»»åŠ¡ {task_id} å›è°ƒæˆåŠŸ")
    except requests.exceptions.ConnectionError:
        logger.error(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ°å›è°ƒæœåŠ¡ï¼ˆ8001ç«¯å£æœªå¯åŠ¨ï¼Ÿï¼‰")
    except requests.exceptions.Timeout:
        logger.error(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼šè¯·æ±‚è¶…æ—¶ï¼ˆå›è°ƒæœåŠ¡å“åº”è¿‡æ…¢ï¼‰")
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡ {task_id} å›è°ƒå¤±è´¥ï¼š{str(e)} | å¼‚å¸¸ç±»å‹: {type(e)}", exc_info=True)

# ===================== æ ¸å¿ƒä¸šåŠ¡ä»»åŠ¡ =====================
@celery_app.task(bind=True, max_retries=0, ignore_result=False)
def process_task(self, task_id: str, data: dict):
    """æ ¸å¿ƒä¸šåŠ¡ä»»åŠ¡ï¼ˆæ—¥å¿—ç‰ˆï¼‰"""
    try:
        import time
        logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†ä»»åŠ¡ | ä¸šåŠ¡ID: {task_id} | ä»»åŠ¡æ•°æ®: {data}")
        time.sleep(1)  # æ¨¡æ‹Ÿä¸šåŠ¡å¤„ç†è€—æ—¶
        
        task_result = {
            "status": "success",
            "business_task_id": task_id,
            "data": data,
            "message": "ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
            "process_time": 1.0
        }
        logger.info(f"âœ… å®Œæˆå¤„ç†ä»»åŠ¡ | ä¸šåŠ¡ID: {task_id}")
        return task_result
    
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ å¤„ç†ä»»åŠ¡å¤±è´¥ | ä¸šåŠ¡ID: {task_id} | é”™è¯¯ä¿¡æ¯: {error_msg}", exc_info=True)
        raise e

# ===================== å…¨å±€ä¿¡å·å›è°ƒ =====================
@task_success.connect(sender=process_task)
def handle_task_success_signal(sender=None, result=None, **kwargs):
    """ä»»åŠ¡æˆåŠŸå…¨å±€ä¿¡å·å›è°ƒ"""
    celery_task_id = sender.request.id
    task_kwargs = sender.request.kwargs
    business_task_id = task_kwargs.get("task_id") or celery_task_id
    
    logger.info(f"ğŸš€ å…¨å±€æˆåŠŸä¿¡å·è§¦å‘ | Celery ID: {celery_task_id} | ä¸šåŠ¡ID: {business_task_id}")
    send_callback(
        task_id=business_task_id,
        status="success",
        result=result
    )

@task_failure.connect(sender=process_task)
def handle_task_failure_signal(sender=None, exception=None, **kwargs):
    """ä»»åŠ¡å¤±è´¥å…¨å±€ä¿¡å·å›è°ƒ"""
    celery_task_id = sender.request.id
    task_kwargs = sender.request.kwargs
    business_task_id = task_kwargs.get("task_id") or celery_task_id
    
    logger.error(f"ğŸš¨ å…¨å±€å¤±è´¥ä¿¡å·è§¦å‘ | Celery ID: {celery_task_id} | ä¸šåŠ¡ID: {business_task_id} | å¼‚å¸¸: {str(exception)}")
    send_callback(
        task_id=business_task_id,
        status="failed",
        error=str(exception)
    )

# ===================== æ¨¡å—åŠ è½½éªŒè¯ =====================
if __name__ == "__main__":
    logger.info("âœ… Celeryä»»åŠ¡æ¨¡å—åŠ è½½æˆåŠŸï¼æ— è¯­æ³•é”™è¯¯ï¼")
    logger.info(f"âœ… å›è°ƒæœåŠ¡åœ°å€ï¼š{CALLBACK_URL}")
    logger.info(f"âœ… Redisè¿æ¥åœ°å€ï¼šredis://localhost:6379/0")
    logger.info(f"âœ… é€‚é…ç³»ç»Ÿï¼šLinuxï¼ˆCeleryæ± ç±»å‹ï¼špreforkï¼‰")
    logger.info(f"âœ… æ—¥å¿—å­˜å‚¨è·¯å¾„ï¼š{LOG_DIR}")